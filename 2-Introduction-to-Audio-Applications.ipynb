{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPN7tVIob//GYF1GO9fVcxF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/Audio-Data-with-HuggingFace/blob/main/2-Introduction-to-Audio-Applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio classification with a pipeline"
      ],
      "metadata": {
        "id": "SFrFJJJmll51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's install the datasets library."
      ],
      "metadata": {
        "id": "RIii0J6UtiOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU datasets"
      ],
      "metadata": {
        "id": "woQrG2iul3PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's load the dataset and then set the sampling rate of it."
      ],
      "metadata": {
        "id": "oO7_0p1jtpJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data"
      ],
      "metadata": {
        "id": "3JsphDAwzx63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra1Fpa2Yf7qs"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Audio\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let me set the pipeline."
      ],
      "metadata": {
        "id": "TmSusD9rtzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"audio-classification\",\n",
        "    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n",
        ")"
      ],
      "metadata": {
        "id": "27lnK8EfmHGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see how to work the pipeline, let's get an example."
      ],
      "metadata": {
        "id": "MBU9WVo9t5nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]"
      ],
      "metadata": {
        "id": "sOlGnFoAmqkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example"
      ],
      "metadata": {
        "id": "cr-JgjC_n_o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we'll pass arrays of the example into the pipeline."
      ],
      "metadata": {
        "id": "YeaBaZ9OuC9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"audio\"][\"array\"]"
      ],
      "metadata": {
        "id": "RoPHTnw_oEjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "id": "iABWCTrLn8-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline made a prediction and guessed the label. Let's check if it is correct."
      ],
      "metadata": {
        "id": "LMKZzjq-uR93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = minds.features[\"intent_class\"].int2str\n",
        "id2label(example[\"intent_class\"])"
      ],
      "metadata": {
        "id": "8x66nJstoM2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic speech recognition with a pipeline"
      ],
      "metadata": {
        "id": "xMX2nqMHs9BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transcribe an audio recording, we can use the automatic-speech-recognition pipeline from ü§ó Transformers."
      ],
      "metadata": {
        "id": "i4UKI3sPtaSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "asr = pipeline(\"automatic-speech-recognition\")"
      ],
      "metadata": {
        "id": "OhGus8FZszKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take an example from the dataset and pass its raw data to the pipeline:"
      ],
      "metadata": {
        "id": "C5bXuWaKtfDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "id": "y4G4mBaUtVNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs compare this output to what the actual transcription for this example is:"
      ],
      "metadata": {
        "id": "Ft7O9KRgu2t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"english_transcription\"]"
      ],
      "metadata": {
        "id": "TWpyTFAKu4x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs try this for the German split of the MINDS-14. Load the ‚Äúde-DE‚Äù subset. First, let me load the dataset and set it."
      ],
      "metadata": {
        "id": "kCrHNHe0vROX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Audio\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"de-DE\", split=\"train\")\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "V6vYBMLWvSEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an example and see what the transcription is supposed to be:"
      ],
      "metadata": {
        "id": "z2Gvx2p3vdXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "example[\"transcription\"]"
      ],
      "metadata": {
        "id": "h405BOV0vUfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we're going to do now is to find a pre-trained ASR model for German language on the ü§ó Hub, instantiate a pipeline, and transcribe the example:"
      ],
      "metadata": {
        "id": "t3F5OtyKvkzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "asr = pipeline(\"automatic-speech-recognition\", model=\"maxidl/wav2vec2-large-xlsr-german\")\n",
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "id": "5qqluYB7vrVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio generation with a pipeline"
      ],
      "metadata": {
        "id": "gs_FKx4_v_MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let me install the last version of Transformers."
      ],
      "metadata": {
        "id": "5OgFD5ubxe4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU transformers"
      ],
      "metadata": {
        "id": "pKrI12F6wAyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "id": "lCv3zVT6xoxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating speech"
      ],
      "metadata": {
        "id": "WRv1m_UMxuzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get started to define a text-to-speech pipeline."
      ],
      "metadata": {
        "id": "rq-C4NPMx4rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-to-speech\", model=\"suno/bark-small\")"
      ],
      "metadata": {
        "id": "Y6-oIMRSxv8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is as simple as passing some text through the pipeline. All the preprocessing will be done for us under the hood:"
      ],
      "metadata": {
        "id": "oClp4ChOyEEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Ladybugs have had important roles in culture and religion, being associated with luck, love, fertility and prophecy. \"\n",
        "output = pipe(text)"
      ],
      "metadata": {
        "id": "dkK9igkYx_Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "1aer8MsJyxdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me listen to the output."
      ],
      "metadata": {
        "id": "pcpR-_oWy93f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "bKD8tbH6yI0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that Bark, is a multilingual model. Now let's take a look at another example with a text in French."
      ],
      "metadata": {
        "id": "FwronIPGzGvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr_text = \"Contrairement √† une id√©e r√©pandue, le nombre de points sur les √©lytres d'une coccinelle ne correspond pas √† son √¢ge, ni en nombre d'ann√©es, ni en nombre de mois. \"\n",
        "output = pipe(fr_text)\n",
        "Audio(output[\"audio\"], rate=output[\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "aAtdbdU5zGHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating music"
      ],
      "metadata": {
        "id": "ODC5b0N7z9Rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For music generation, Let me define a text-to-audio pipeline:"
      ],
      "metadata": {
        "id": "wK7eohGk0COx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_pipe = pipeline(\"text-to-audio\", model=\"facebook/musicgen-small\")"
      ],
      "metadata": {
        "id": "kWp4j-MYz-Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs create a text description of the music we‚Äôd like to generate:"
      ],
      "metadata": {
        "id": "3P-q0hjg0LwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"90s rock song with electric guitar and heavy drums\""
      ],
      "metadata": {
        "id": "OoPfDYWN0H3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we can control the length of the generated output by passing an additional max_new_tokens parameter to the model."
      ],
      "metadata": {
        "id": "WFd4fkHm0U90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_params = {\"max_new_tokens\": 512}\n",
        "\n",
        "output = music_pipe(text, forward_params=forward_params)\n",
        "Audio(output[\"audio\"][0], rate=output[\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "QbvC4U8p0OcW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}