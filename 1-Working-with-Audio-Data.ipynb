{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMt8ui52TazQjI47egSbHZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/Audio-Data-with-HuggingFace/blob/main/1-Working-with-Audio-Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and explore an audio dataset"
      ],
      "metadata": {
        "id": "XGWl8W23BOa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf5rtuWO22RF"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets[audio]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "datasets.__version__"
      ],
      "metadata": {
        "id": "KY1EHx5N3jvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
        "minds"
      ],
      "metadata": {
        "id": "kCRp9_dp3zL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minds"
      ],
      "metadata": {
        "id": "Bj2nOPOg38S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(minds.features[\"lang_id\"])\n",
        "print(minds.features[\"lang_id\"].num_classes)\n",
        "print(minds.features[\"lang_id\"].names)"
      ],
      "metadata": {
        "id": "-DfVuiU87AS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minds.features[\"intent_class\"]"
      ],
      "metadata": {
        "id": "MUfCBwR_60ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(minds[\"intent_class\"])"
      ],
      "metadata": {
        "id": "oU0tCea-6jIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "example"
      ],
      "metadata": {
        "id": "cwWPgDzn5BQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = minds.features[\"intent_class\"].int2str\n",
        "id2label"
      ],
      "metadata": {
        "id": "Q_emDmn0771v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = minds.features[\"intent_class\"].int2str\n",
        "id2label(example[\"intent_class\"])"
      ],
      "metadata": {
        "id": "2SCc0tpO5n4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\"lang_id\", \"english_transcription\"]\n",
        "minds = minds.remove_columns(columns_to_remove)\n",
        "minds"
      ],
      "metadata": {
        "id": "ONTkQ1sZ6ZJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "ovswrLEx9rwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def generate_audio():\n",
        "    example = minds.shuffle()[0]\n",
        "    audio = example[\"audio\"]\n",
        "    return (\n",
        "        audio[\"sampling_rate\"],\n",
        "        audio[\"array\"],\n",
        "    ), id2label(example[\"intent_class\"])\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Column():\n",
        "        for _ in range(4):\n",
        "            audio, label = generate_audio()\n",
        "            output = gr.Audio(audio, label=label)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "LZk0Vcc49mKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds.shuffle()[0]\n",
        "example"
      ],
      "metadata": {
        "id": "VuhRRlrf-H8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "array = example[\"audio\"][\"array\"]\n",
        "sampling_rate = example[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "plt.figure().set_figwidth(12)\n",
        "librosa.display.waveshow(array, sr=sampling_rate)"
      ],
      "metadata": {
        "id": "E_nJM2_f_RJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Preprocessing an audio dataset"
      ],
      "metadata": {
        "id": "vR0wZn2OBKIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resampling the audio data"
      ],
      "metadata": {
        "id": "TQl8wUGOBHK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minds[0]"
      ],
      "metadata": {
        "id": "DH63tyDPAbye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minds[0][\"audio\"]"
      ],
      "metadata": {
        "id": "xTFhjDMWAfBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one audio sample\n",
        "audio_sample = minds[0][\"audio\"]\n",
        "\n",
        "# Print the sampling rate\n",
        "print(audio_sample[\"sampling_rate\"])"
      ],
      "metadata": {
        "id": "s75N-togARey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Audio\n",
        "\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "deba1yzpAkoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minds[0]"
      ],
      "metadata": {
        "id": "Z2KEyUYQAxgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering the dataset"
      ],
      "metadata": {
        "id": "JKmcYpQnBAw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DURATION_IN_SECONDS = 20.0\n",
        "\n",
        "def is_audio_length_in_range(input_length):\n",
        "    return input_length < MAX_DURATION_IN_SECONDS"
      ],
      "metadata": {
        "id": "6IqeUrzjBB8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use librosa to get example's duration from the audio file\n",
        "new_column = [librosa.get_duration(path=x) for x in minds[\"path\"]]\n",
        "minds = minds.add_column(\"duration\", new_column)\n",
        "\n",
        "# use ðŸ¤— Datasets' `filter` method to apply the filtering function\n",
        "minds = minds.filter(is_audio_length_in_range, input_columns=[\"duration\"])\n",
        "\n",
        "# remove the temporary helper column\n",
        "minds = minds.remove_columns([\"duration\"])\n",
        "minds"
      ],
      "metadata": {
        "id": "tIJY8gNgByZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing audio data"
      ],
      "metadata": {
        "id": "Jl0HmVwnCRU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "951cROitCPJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "    features = feature_extractor(\n",
        "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], padding=True\n",
        "    )\n",
        "    return features"
      ],
      "metadata": {
        "id": "SDJYtUj8DGut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minds = minds.map(prepare_dataset)\n",
        "minds"
      ],
      "metadata": {
        "id": "zEr9de-oDGk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "example = minds[0]\n",
        "input_features = example[\"input_features\"]\n",
        "\n",
        "plt.figure().set_figwidth(12)\n",
        "librosa.display.specshow(\n",
        "    np.asarray(input_features[0]),\n",
        "    x_axis=\"time\",\n",
        "    y_axis=\"mel\",\n",
        "    sr=feature_extractor.sampling_rate,\n",
        "    hop_length=feature_extractor.hop_length,\n",
        ")\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "tmFmi71hDU0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "0w7CBcd9FO66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming audio data"
      ],
      "metadata": {
        "id": "lmvetRP3FaiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gigaspeech = load_dataset(\"speechcolab/gigaspeech\", \"xs\", streaming=True)"
      ],
      "metadata": {
        "id": "hcZLdHUqFbao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(gigaspeech[\"train\"]))"
      ],
      "metadata": {
        "id": "CGfzrO7IJsQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gigaspeech_head = gigaspeech[\"train\"].take(2)\n",
        "list(gigaspeech_head)"
      ],
      "metadata": {
        "id": "u7wHYheEKWJL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}